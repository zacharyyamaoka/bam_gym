{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aff0f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e958c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "{'#': 0, 's': {'obs': 0}, 'a': 1, 'r': -1}\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "with open('/home/bam/other_bam_packages/bam_gym/dataset/sarsa_0000.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        dataset.append(json.loads(line))\n",
    "\n",
    "\n",
    "print(len(dataset))\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4140224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = 10  # assuming actions are between 0 and 9\n",
    "reward_sum = torch.zeros(num_actions, dtype=torch.float32)\n",
    "action_count = torch.zeros(num_actions, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52599df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in dataset:\n",
    "    action = entry['a']\n",
    "    reward = entry['r']\n",
    "    reward_sum[action] += reward\n",
    "    action_count[action] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b3de571",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_reward = torch.where(\n",
    "    action_count > 0,\n",
    "    reward_sum / action_count,\n",
    "    torch.zeros_like(reward_sum)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1baf53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -70., -104.,   92., -106.,  -93.,  -28.,  -95.,  -87., -107.,  -82.])\n",
      "tensor([-0.7778, -0.9630,  1.0000, -0.8983, -0.9588, -0.2917, -0.8879, -0.9355,\n",
      "        -1.0000, -0.8913])\n",
      "\n",
      "Best action is 2 with estimated average reward 1.00\n"
     ]
    }
   ],
   "source": [
    "print(reward_sum)\n",
    "print(avg_reward)\n",
    "\n",
    "best_action = torch.argmax(avg_reward).item()\n",
    "print(f\"\\nBest action is {best_action} with estimated average reward {avg_reward[best_action]:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
